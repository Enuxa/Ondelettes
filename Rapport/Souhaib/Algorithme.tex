
\newpage

\part{Algorithmes d'encodage et de décodage}

\section{Cadre théorique}

D'un point de vue pratique, les fonctions sont représentées comme des fonctions en escalier, qui de plus sont à support bornés (disons sur $[0, 1[$). C'est-à-dire que l'on manipule des fonctions $f \in L^2(\mathbb{R})$ de la forme $$f = \sum_{j = 0}^{2^{N_0} - 1} a_j \mathbbm{1}_{[2^{-N_0}j, 2^{-N_0}(j+1)[}$$

%On veut trouver les coefficients de $f$ dans l'espace vectoriel $V_{N_0} = V_0 \stackrel{\perp}{\oplus} W_0 \stackrel{\perp}{\oplus} \cdots \stackrel{\perp}{\oplus} W_{N_0}$ .

On rappelle qu'on peut décomposer toute fonction $f \in L_2(\mathbb{R})$ ainsi : $$f = \sum_{k \in \mathbb{Z}} \langle \varphi_{0,k}, f \rangle \varphi_{0,k} + \sum_{\substack{n \in \mathbb{N} \\ k \in \mathbb{Z}}} \langle \psi_{n, k}, f \rangle \psi_{n, k}$$

Le calcul des coefficients s'en retrouve ainsi simplifié :

\begin{align*}
	\langle f, \psi_{n, k} \rangle &= \int_0^1 f(t) \overline{\psi_{n, k}(t)} dt \\
	&= \sum_{j=0}^{N-1} \int_{\frac j N}^{\frac{j+1}N} a_j \overline{\psi_{n, k}(t)} dt \\
	&= \sum_{j=0}^{N-1} \int_{\frac j N}^{\frac{j+1}N} a_j \overline{\frac{1}{\sqrt{2^n}} \psi(2^n t - \frac{k}{N})} dt \\
	&= \frac{1}{\sqrt{2^{3n}}} \sum_{j=0}^{N-1} a_j \int_{2^n \frac{j}N - k}^{2^n\frac{j+1}N - \frac{k}{N}} \overline{\psi(u)} du \quad \text{où $2^nt - \frac{k}{N} = u$} \\
	&= \frac{1}{\sqrt{2^{3n}}} \sum_{j=0}^{N-1} a_j \left(\Psi\left(2^n\frac{j+1}N - \frac{k}{N}\right) - \Psi\left(2^n\frac{j}N - \frac{k}{N}\right)\right) \\
	\langle f, \varphi_{0, k} \rangle &= \int_0^1 f(t) \overline{\varphi_{0, k}(t)} dt \\
	&= \sum_{j=0}^{N-1} \int_{\frac j N}^{\frac{j+1}N} a_j \overline{\varphi_{0, k}(t)} dt \\
	&= \sum_{j=0}^{N-1} \int_{\frac j N}^{\frac{j+1}N} a_j \overline{\varphi(t - k)} dt \\
	&= \sum_{j=0}^{N-1} a_j \int_{\frac{j}N - \frac{k}{N}}^{\frac{j+1}N - \frac{k}{N}} \overline{\varphi(u)} du \quad \text{où $t - \frac{k}{N} = u$} \\
	&= \sum_{j=0}^{N-1} a_j \left(\Phi\left(\frac{j+1}N - \frac{k}{N}\right) - \Phi\left(\frac{j}N - \frac{k}{N}\right)\right)
\end{align*}

où $\Psi$ est une primitive de $\overline{\psi}$, $\Phi$ est une primitive de $\overline{\phi}$ et $N = 2^{N_0}$.

Étant face à des fonctions en escalier avec un pas fixe, on peut les représenter comme des vecteurs de $\mathbb{R}^N$, où la $(j+1)$-ième coordonnée est la valeur prise sur le $(j+1)$-ième intervalle. On note $\tilde{f} = (a_j, a_1 \cdots a_N)$ et $\DS \widetilde{\psi}_{n, k} = \left(\frac{1}{\sqrt{2^{3n}}} (\Psi(2^n j - k) - \Psi(2^n (j+1) - k))\right)_{j = 0, 1 \cdots N - 1}$, on a alors 

$$\langle f, \psi_{n, k} \rangle =\widetilde{\psi}_{n, k} \times \transp{\widetilde{f}}$$

De plus, en définissant $S_n = (\langle f, \psi_{n, k}\rangle)_{k = 0, 1 \cdots s(n)}$, avec $s(n)$ le plus grand $k$ que l'on souhaitera calculer, et

$$P_n = 
\left(
	\begin{array}{c}
		\widetilde{\psi}_{n, 0} \\
		\widetilde{\psi}_{n, 1} \\
		\vdots \\
		\widetilde{\psi}_{n, s(n)} 
	\end{array}
\right)$$

on a enfin $$S_n = P_n\times\transp{\tilde{f} }$$

Chaque $P_n$ est alors le projecteur de $f$ sur l'espace de détails $W_n$, les coefficients sont alors stockés dans le vecteur $S_n$.

\begin{myrem}
	La matrice $\widetilde{f}$ est de taille $1 \times N$, $P_n$ de taille $s(n) \times N$ et $S_n$ de taille $1 \times s(n)$.
\end{myrem}

L'algorithme de compression consiste alors en le remplissage des matrices de projection pour chaque niveau de détail et en la multiplication pour obtenir chaque $S_n$. Nous proposons l'algorithme naïf suivant :

\begin{algorithm}
	\begin{algorithmic}[1]
		\Procedure{Encoder}{$\Psi$, $\widetilde{f}$, $N_0$, $s$}
			\State $S_m := \Phi(1)-\Phi(0)$
			\State $P_0 := $ Construire($\Psi$, 0, $s(0)$)
			\For{$n = 0, 1 \cdots N_0$}
				\State $P_n :=$ Construire($\Psi$, $n$, s(n))
				\State $S_n := P_n\times \transp{\widetilde{f}}$
		
			\EndFor
			\State \Return $S_m,(S_0, S_{-1}, S_{1} \cdots S_{N_0}, S_{-N_0})$
		\EndProcedure

		\Statex

		\Procedure{Décoder}{$\psi$, $S_m$, $A=(\alpha_{n, k})_{n, k}$, $N_0$, $s(n)$}
		\For{$x = 0, 2^{-N_0}, 2\times 2^{-N_0} \cdots, 1$}
		\State $f(x) := S_m$
		\For{$n = 0, 1 \cdots, N_0$}
		\For{$k = 0, 1 \cdots, s(n)$}
		\State $f(x) := f(x) + \alpha_{n, k} \times \psi(2^{-n} x - k)$
		\EndFor
		\EndFor
		\EndFor
		\State \Return $f$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\subsection{Validation de l'algorithme}

Vérifier que cet algorithme est correct consiste à vérifier que les approximations que l'on a du faire pour passer de valeurs infinies à des valeurs finies pour $n$ et $k$ ne sont pas préjudiciables à la validité des résultats produits. Il s'agit donc de vérifier que les valeurs de $n$ et $k$ enlevées sont négligeables. En effet,  le reste de l'algorithme ne doit pas donner lieu a des erreurs : la formule utilisée est celle qui a été définie plus tôt, et il est certain de terminer. 

% sensibilité
\subsubsection{Coordonnées $n\geqslant N_0$}

La valeur de $\langle f,\psi_{n,k}\rangle$ représente à peu près la «variation» de $f$ dans l'intervalle $[2^{-n}k,2^{-n}(k+1)]$.

Étant donné que $f$ est échantillonnée avec une fréquence de $2^{-N_0}$, $f$ est constante sur les intervalles $[2^{-n}k,2^{-n}(k+1)]$ pour $n\geqslant N_0$.

Concrètement, pour un $n$ aussi grand, on a $\langle f,\psi_{n,k}\rangle = \int_0^1 f(t) \overline{\psi_{n, k}(t)}dt \approx \int_{2^{-n}k}^{2^{-n}(k+1)} f(t) \overline{\psi_{n, k}(t)}dt$ car on suppose que $\psi_{n,k}$ est négligeable en dehors de $[2^{-n}k,2^{-n}(k+1)]$.

Cette valeur est négligeable, car sur l'intervalle $[2^{-n}k,2^{-n}(k+1)]$, la fonction $f$ est constante et $\psi_{n,k}$ est de moyenne nulle.

Dans la pratique, cela correspond a des intervalles qui sont plus petits que la fréquence d'échantillonnage: la fonction est donc constante sur l'intervalle, et comme l'ondelette est de moyenne nulle, les valeurs qui lui sont associées sont bien négligeables. 


\subsubsection{Coordonnées $n < 0$}

De même que précédemment, $\langle f,\psi_{n,k}\rangle$ représente la variation dans l'intervalle $[2^{-n}k,2^{-n}(k+1)]$. Pour un $n$ négatif, cet intervalle vaut au moins le double du domaine de définition de la fonction. Dès lors, les estimations de la variation ne seront pas significatifs.



\subsubsection{Coordonnées $k$}

On veut obtenir un recouvrement minimal de $[0,N[$ avec les intervalles disjoints $[2^{n}k,2^{n}(k+1)[$ .

Pour que $[2^{n}k,2^{n}(k+1)[\cap[0,N[\neq\emptyset$, il faut que $0\le k< 2^{-n}N$ .

\begin{myexmpl}
	Nous allons décomposer la fonction $f(t)=t$ définie sur $[0, 1]$ dans la base de l'ondelette de Haar, la famille donnée par
	$$\psi_{n, k}(t) = \left\{
	\begin{array}{cc}
		\sqrt{2}^n & 2^{-n}k \leqslant t < 2^{-n} (k+1/2) \\
		-\sqrt{2}^n & 2^{-n}(k+1/2) \leqslant t < 2^{-n} (k+1)
	\end{array}
	\right.$$
	
	Les coefficients sont 
	
	\begin{align*}
		\alpha_{n, k} &= \int_{0}^{1} \psi_{n, k}(t) f(t) dt \\
		&= \sqrt{2^n} \int_{2^{-n}k}^{2^{-n}(k+1/2)} t dt - \sqrt{2^n} \int_{2^{-n}(k+1/2)}^{2^{-n}(k+1)} t dt \\
		&= \sqrt{2^n} \frac{t^2}{2} \bigg \vert_{2^{-n} k}^{2^{-n}(k+1/2)} - \sqrt{2^n} \frac{t^2}{2} \bigg \vert_{2^{-n} (k+1/2)}^{2^{-n}(k+1)} \\
		&= \frac{1}{\sqrt{2}^{3n + 4}}
	\end{align*}
\end{myexmpl}



\subsection{Optimisation et compression}

L'intérêt de ce type d'algorithme est de pouvoir compresser les informations pour encoder le signal en perdant le moins d'informations possible. Pour cela, on peut agir à deux niveaux.

\subsubsection{Niveaux de détail}
	Le premier point sur lequel on peut travailler est le niveau de détail. Lorsqu'on observe l'algorithme, on peut voir que les coefficients pour les premières valeurs de $n$ sont moins nombreux, du fait qu'il suffise de quelques ondelettes pour parcourir le domaine de définition. Ce sont ces coefficients qui donnent la structure générale du signal et sont plus impactant que les niveaux de détails suivants. On peut donc penser qu'il est possible d'arrêter l'algorithme plus après moins d'itérations que ce que le l'on a défini précédemment car les détails suivant seront négligeables. 

\subsubsection{Encodage des coefficients}
	Un autre point sur lequel on peut travailler est l'encodage des coefficients, ou tout du moins leur niveau de précision. En effet, il n'est pas forcément utile d'avoir une grande précision sur la valeur du coefficient. De plus, à partir d'un certain rang, comme on l'a pensé précédemment, la plupart des coefficients sont négligeables. Pour optimiser le volume des coefficients formés, il peut être utile de ne stocker que les coefficients non nuls, qui seront bien moins nombreux.

	On peut aussi donner de moins grandes précisions aux coefficients qui correspondent aux variations plus localisées et donc moins sensibles à l'œil nu.
	